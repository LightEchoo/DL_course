{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_index arm_name trial_status generation_method  val_accuracy  \\\n0             0      0_0    COMPLETED             Sobol      0.826649   \n1             1      1_0    COMPLETED             Sobol      0.876759   \n2             2      2_0    COMPLETED             Sobol      0.902695   \n3             3      3_0    COMPLETED             Sobol      0.880441   \n4             4      4_0    COMPLETED             Sobol      0.890542   \n5             5      5_0    COMPLETED             Sobol      0.812183   \n6             6      6_0    COMPLETED             Sobol      0.869107   \n7             7      7_0    COMPLETED             Sobol      0.906752   \n8             8      8_0    COMPLETED           BoTorch      0.904797   \n9             9      9_0    COMPLETED           BoTorch      0.906758   \n10           10     10_0    COMPLETED           BoTorch      0.906402   \n11           11     11_0    COMPLETED           BoTorch      0.905905   \n12           12     12_0    COMPLETED           BoTorch      0.883293   \n13           13     13_0    COMPLETED           BoTorch      0.921344   \n14           14     14_0    COMPLETED           BoTorch      0.920113   \n15           15     15_0    COMPLETED           BoTorch      0.931341   \n16           16     16_0    COMPLETED           BoTorch      0.931343   \n17           17     17_0    COMPLETED           BoTorch      0.930344   \n18           18     18_0    COMPLETED           BoTorch      0.928382   \n19           19     19_0    COMPLETED           BoTorch      0.930605   \n20           20     20_0    COMPLETED           BoTorch      0.924492   \n21           21     21_0    COMPLETED           BoTorch      0.924346   \n22           22     22_0    COMPLETED           BoTorch      0.930836   \n23           23     23_0    COMPLETED           BoTorch      0.931023   \n24           24     24_0    COMPLETED           BoTorch      0.931467   \n25           25     25_0    COMPLETED           BoTorch      0.931804   \n26           26     26_0    COMPLETED           BoTorch      0.927996   \n27           27     27_0    COMPLETED           BoTorch      0.930227   \n28           28     28_0    COMPLETED           BoTorch      0.932245   \n29           29     29_0    COMPLETED           BoTorch      0.928285   \n30           30     30_0    COMPLETED           BoTorch      0.930878   \n31           31     31_0    COMPLETED           BoTorch      0.931342   \n32           32     32_0    COMPLETED           BoTorch      0.928506   \n33           33     33_0    COMPLETED           BoTorch      0.929612   \n34           34     34_0    COMPLETED           BoTorch      0.928910   \n35           35     35_0    COMPLETED           BoTorch      0.928544   \n36           36     36_0    COMPLETED           BoTorch      0.925076   \n37           37     37_0    COMPLETED           BoTorch      0.929094   \n38           38     38_0    COMPLETED           BoTorch      0.931047   \n39           39     39_0    COMPLETED           BoTorch      0.922017   \n40           40     40_0    COMPLETED           BoTorch      0.929937   \n41           41     41_0    COMPLETED           BoTorch      0.931155   \n42           42     42_0    COMPLETED           BoTorch      0.929270   \n43           43     43_0    COMPLETED           BoTorch      0.923895   \n44           44     44_0    COMPLETED           BoTorch      0.932512   \n45           45     45_0    COMPLETED           BoTorch      0.924869   \n46           46     46_0    COMPLETED           BoTorch      0.929293   \n47           47     47_0    COMPLETED           BoTorch      0.925965   \n48           48     48_0    COMPLETED           BoTorch      0.928744   \n49           49     49_0    COMPLETED           BoTorch      0.921815   \n\n      val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0   0.632487  0.753653       0.609964    0.691167  0.000001      0.096349   \n1   0.810590  0.310385       0.820969    0.803478  0.001084      0.474500   \n2   0.816620  0.246278       0.832687    0.807861  0.000732      0.349536   \n3   0.813905  0.301987       0.836453    0.798037  0.016307      0.007049   \n4   0.796962  0.276153       0.806222    0.788968  0.000087      0.299568   \n5   0.670001  0.598767       0.658047    0.693985  0.000002      0.142983   \n6   0.713430  0.443356       0.724637    0.708917  0.000007      0.069830   \n7   0.825898  0.237442       0.841261    0.814406  0.001475      0.208630   \n8   0.820374  0.241392       0.838710    0.808427  0.001927      0.256962   \n9   0.827038  0.236193       0.835439    0.820312  0.001854      0.259384   \n10  0.825203  0.237058       0.836321    0.816084  0.001149      0.231935   \n11  0.823945  0.237669       0.837597    0.816305  0.001215      0.227262   \n12  0.822653  0.293328       0.826884    0.818603  0.001201      0.212927   \n13  0.829605  0.200420       0.835081    0.825778  0.003261      0.181830   \n14  0.823641  0.202998       0.838411    0.814590  0.001607      0.249531   \n15  0.825837  0.173852       0.834198    0.818445  0.002447      0.194741   \n16  0.825308  0.173988       0.836522    0.819715  0.001821      0.174627   \n17  0.820531  0.177285       0.843120    0.802851  0.002178      0.192044   \n18  0.816231  0.182909       0.840804    0.795912  0.004863      0.126065   \n19  0.827112  0.175646       0.824020    0.831566  0.001781      0.105353   \n20  0.818658  0.194072       0.803174    0.837278  0.004579      0.187194   \n21  0.810814  0.191105       0.837076    0.789558  0.003101      0.122990   \n22  0.823662  0.174842       0.834065    0.817389  0.001044      0.136415   \n23  0.822742  0.174591       0.838991    0.809842  0.001428      0.138828   \n24  0.828557  0.174540       0.822700    0.834633  0.007717      0.038824   \n25  0.826737  0.172587       0.835045    0.822671  0.006317      0.064065   \n26  0.816959  0.181844       0.837481    0.799061  0.000999      0.178062   \n27  0.820037  0.176949       0.842783    0.802240  0.001017      0.085390   \n28  0.828220  0.171595       0.834372    0.823310  0.001694      0.143371   \n29  0.825864  0.181127       0.816282    0.838710  0.006746      0.056740   \n30  0.823761  0.176168       0.837977    0.812122  0.005780      0.086623   \n31  0.824092  0.173852       0.838910    0.814581  0.002650      0.218267   \n32  0.810207  0.180810       0.846359    0.790988  0.006640      0.015518   \n33  0.810810  0.178682       0.852856    0.787512  0.003081      0.073780   \n34  0.816401  0.180558       0.842264    0.797381  0.018916      0.029491   \n35  0.822365  0.181710       0.811102    0.834620  0.001413      0.156723   \n36  0.794416  0.189463       0.857818    0.761617  0.006000      0.146366   \n37  0.820831  0.180007       0.825112    0.816698  0.000541      0.107974   \n38  0.825692  0.174317       0.829511    0.822382  0.002559      0.206471   \n39  0.778720  0.193512       0.852450    0.767553  0.010812      0.024670   \n40  0.824038  0.177415       0.827747    0.824270  0.001041      0.112319   \n41  0.825115  0.174924       0.829401    0.822980  0.002541      0.161519   \n42  0.821059  0.181067       0.825488    0.818360  0.028608      0.053110   \n43  0.802210  0.193589       0.856237    0.764752  0.004537      0.033237   \n44  0.829085  0.171494       0.833407    0.826962  0.005099      0.071276   \n45  0.807986  0.190782       0.850218    0.775249  0.007834      0.076058   \n46  0.823330  0.178738       0.819310    0.828129  0.000659      0.146524   \n47  0.816944  0.187925       0.816110    0.823992  0.028486      0.022405   \n48  0.819471  0.182192       0.838004    0.802784  0.005551      0.070264   \n49  0.780488  0.201478       0.860354    0.746312  0.008412      0.000000   \n\n    batch_size  embedding_dim  \n0           32              5  \n1            4             20  \n2            8              5  \n3            4             20  \n4            8             20  \n5            8              5  \n6           16             20  \n7            8              5  \n8            8             20  \n9            8              5  \n10           8              5  \n11           8              5  \n12           4              5  \n13          16              5  \n14          16              5  \n15          32              5  \n16          32              5  \n17          32              5  \n18          32              5  \n19          32              5  \n20          32              5  \n21          32              5  \n22          32              5  \n23          32              5  \n24          32              5  \n25          32              5  \n26          32              5  \n27          32              5  \n28          32              5  \n29          32              5  \n30          32              5  \n31          32              5  \n32          32              5  \n33          32              5  \n34          32              5  \n35          32              5  \n36          32              5  \n37          32              5  \n38          32              5  \n39          32              5  \n40          32              5  \n41          32              5  \n42          32              5  \n43          32              5  \n44          32              5  \n45          32              5  \n46          32              5  \n47          32              5  \n48          32              5  \n49          32              5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.826649</td>\n      <td>0.632487</td>\n      <td>0.753653</td>\n      <td>0.609964</td>\n      <td>0.691167</td>\n      <td>0.000001</td>\n      <td>0.096349</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.876759</td>\n      <td>0.810590</td>\n      <td>0.310385</td>\n      <td>0.820969</td>\n      <td>0.803478</td>\n      <td>0.001084</td>\n      <td>0.474500</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.902695</td>\n      <td>0.816620</td>\n      <td>0.246278</td>\n      <td>0.832687</td>\n      <td>0.807861</td>\n      <td>0.000732</td>\n      <td>0.349536</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.880441</td>\n      <td>0.813905</td>\n      <td>0.301987</td>\n      <td>0.836453</td>\n      <td>0.798037</td>\n      <td>0.016307</td>\n      <td>0.007049</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.890542</td>\n      <td>0.796962</td>\n      <td>0.276153</td>\n      <td>0.806222</td>\n      <td>0.788968</td>\n      <td>0.000087</td>\n      <td>0.299568</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.812183</td>\n      <td>0.670001</td>\n      <td>0.598767</td>\n      <td>0.658047</td>\n      <td>0.693985</td>\n      <td>0.000002</td>\n      <td>0.142983</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>6_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.869107</td>\n      <td>0.713430</td>\n      <td>0.443356</td>\n      <td>0.724637</td>\n      <td>0.708917</td>\n      <td>0.000007</td>\n      <td>0.069830</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.906752</td>\n      <td>0.825898</td>\n      <td>0.237442</td>\n      <td>0.841261</td>\n      <td>0.814406</td>\n      <td>0.001475</td>\n      <td>0.208630</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>8_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.904797</td>\n      <td>0.820374</td>\n      <td>0.241392</td>\n      <td>0.838710</td>\n      <td>0.808427</td>\n      <td>0.001927</td>\n      <td>0.256962</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>9_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.906758</td>\n      <td>0.827038</td>\n      <td>0.236193</td>\n      <td>0.835439</td>\n      <td>0.820312</td>\n      <td>0.001854</td>\n      <td>0.259384</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>10_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.906402</td>\n      <td>0.825203</td>\n      <td>0.237058</td>\n      <td>0.836321</td>\n      <td>0.816084</td>\n      <td>0.001149</td>\n      <td>0.231935</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>11_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.905905</td>\n      <td>0.823945</td>\n      <td>0.237669</td>\n      <td>0.837597</td>\n      <td>0.816305</td>\n      <td>0.001215</td>\n      <td>0.227262</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>12_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.883293</td>\n      <td>0.822653</td>\n      <td>0.293328</td>\n      <td>0.826884</td>\n      <td>0.818603</td>\n      <td>0.001201</td>\n      <td>0.212927</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>13_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.921344</td>\n      <td>0.829605</td>\n      <td>0.200420</td>\n      <td>0.835081</td>\n      <td>0.825778</td>\n      <td>0.003261</td>\n      <td>0.181830</td>\n      <td>16</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>14_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.920113</td>\n      <td>0.823641</td>\n      <td>0.202998</td>\n      <td>0.838411</td>\n      <td>0.814590</td>\n      <td>0.001607</td>\n      <td>0.249531</td>\n      <td>16</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>15_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931341</td>\n      <td>0.825837</td>\n      <td>0.173852</td>\n      <td>0.834198</td>\n      <td>0.818445</td>\n      <td>0.002447</td>\n      <td>0.194741</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>16_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931343</td>\n      <td>0.825308</td>\n      <td>0.173988</td>\n      <td>0.836522</td>\n      <td>0.819715</td>\n      <td>0.001821</td>\n      <td>0.174627</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>17_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930344</td>\n      <td>0.820531</td>\n      <td>0.177285</td>\n      <td>0.843120</td>\n      <td>0.802851</td>\n      <td>0.002178</td>\n      <td>0.192044</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>18_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928382</td>\n      <td>0.816231</td>\n      <td>0.182909</td>\n      <td>0.840804</td>\n      <td>0.795912</td>\n      <td>0.004863</td>\n      <td>0.126065</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>19_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930605</td>\n      <td>0.827112</td>\n      <td>0.175646</td>\n      <td>0.824020</td>\n      <td>0.831566</td>\n      <td>0.001781</td>\n      <td>0.105353</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>20_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924492</td>\n      <td>0.818658</td>\n      <td>0.194072</td>\n      <td>0.803174</td>\n      <td>0.837278</td>\n      <td>0.004579</td>\n      <td>0.187194</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>21_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924346</td>\n      <td>0.810814</td>\n      <td>0.191105</td>\n      <td>0.837076</td>\n      <td>0.789558</td>\n      <td>0.003101</td>\n      <td>0.122990</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>22_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930836</td>\n      <td>0.823662</td>\n      <td>0.174842</td>\n      <td>0.834065</td>\n      <td>0.817389</td>\n      <td>0.001044</td>\n      <td>0.136415</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>23_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931023</td>\n      <td>0.822742</td>\n      <td>0.174591</td>\n      <td>0.838991</td>\n      <td>0.809842</td>\n      <td>0.001428</td>\n      <td>0.138828</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>24_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931467</td>\n      <td>0.828557</td>\n      <td>0.174540</td>\n      <td>0.822700</td>\n      <td>0.834633</td>\n      <td>0.007717</td>\n      <td>0.038824</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>25_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931804</td>\n      <td>0.826737</td>\n      <td>0.172587</td>\n      <td>0.835045</td>\n      <td>0.822671</td>\n      <td>0.006317</td>\n      <td>0.064065</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>26_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.927996</td>\n      <td>0.816959</td>\n      <td>0.181844</td>\n      <td>0.837481</td>\n      <td>0.799061</td>\n      <td>0.000999</td>\n      <td>0.178062</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>27_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930227</td>\n      <td>0.820037</td>\n      <td>0.176949</td>\n      <td>0.842783</td>\n      <td>0.802240</td>\n      <td>0.001017</td>\n      <td>0.085390</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>28_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.932245</td>\n      <td>0.828220</td>\n      <td>0.171595</td>\n      <td>0.834372</td>\n      <td>0.823310</td>\n      <td>0.001694</td>\n      <td>0.143371</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>29_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928285</td>\n      <td>0.825864</td>\n      <td>0.181127</td>\n      <td>0.816282</td>\n      <td>0.838710</td>\n      <td>0.006746</td>\n      <td>0.056740</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>30_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930878</td>\n      <td>0.823761</td>\n      <td>0.176168</td>\n      <td>0.837977</td>\n      <td>0.812122</td>\n      <td>0.005780</td>\n      <td>0.086623</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>31_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931342</td>\n      <td>0.824092</td>\n      <td>0.173852</td>\n      <td>0.838910</td>\n      <td>0.814581</td>\n      <td>0.002650</td>\n      <td>0.218267</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>32_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928506</td>\n      <td>0.810207</td>\n      <td>0.180810</td>\n      <td>0.846359</td>\n      <td>0.790988</td>\n      <td>0.006640</td>\n      <td>0.015518</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>33_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929612</td>\n      <td>0.810810</td>\n      <td>0.178682</td>\n      <td>0.852856</td>\n      <td>0.787512</td>\n      <td>0.003081</td>\n      <td>0.073780</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>34_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928910</td>\n      <td>0.816401</td>\n      <td>0.180558</td>\n      <td>0.842264</td>\n      <td>0.797381</td>\n      <td>0.018916</td>\n      <td>0.029491</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>35_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928544</td>\n      <td>0.822365</td>\n      <td>0.181710</td>\n      <td>0.811102</td>\n      <td>0.834620</td>\n      <td>0.001413</td>\n      <td>0.156723</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>36_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.925076</td>\n      <td>0.794416</td>\n      <td>0.189463</td>\n      <td>0.857818</td>\n      <td>0.761617</td>\n      <td>0.006000</td>\n      <td>0.146366</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>37_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929094</td>\n      <td>0.820831</td>\n      <td>0.180007</td>\n      <td>0.825112</td>\n      <td>0.816698</td>\n      <td>0.000541</td>\n      <td>0.107974</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>38_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931047</td>\n      <td>0.825692</td>\n      <td>0.174317</td>\n      <td>0.829511</td>\n      <td>0.822382</td>\n      <td>0.002559</td>\n      <td>0.206471</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>39_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.922017</td>\n      <td>0.778720</td>\n      <td>0.193512</td>\n      <td>0.852450</td>\n      <td>0.767553</td>\n      <td>0.010812</td>\n      <td>0.024670</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>40_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929937</td>\n      <td>0.824038</td>\n      <td>0.177415</td>\n      <td>0.827747</td>\n      <td>0.824270</td>\n      <td>0.001041</td>\n      <td>0.112319</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>41_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931155</td>\n      <td>0.825115</td>\n      <td>0.174924</td>\n      <td>0.829401</td>\n      <td>0.822980</td>\n      <td>0.002541</td>\n      <td>0.161519</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>42_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929270</td>\n      <td>0.821059</td>\n      <td>0.181067</td>\n      <td>0.825488</td>\n      <td>0.818360</td>\n      <td>0.028608</td>\n      <td>0.053110</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>43_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.923895</td>\n      <td>0.802210</td>\n      <td>0.193589</td>\n      <td>0.856237</td>\n      <td>0.764752</td>\n      <td>0.004537</td>\n      <td>0.033237</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>44_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.932512</td>\n      <td>0.829085</td>\n      <td>0.171494</td>\n      <td>0.833407</td>\n      <td>0.826962</td>\n      <td>0.005099</td>\n      <td>0.071276</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>45_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924869</td>\n      <td>0.807986</td>\n      <td>0.190782</td>\n      <td>0.850218</td>\n      <td>0.775249</td>\n      <td>0.007834</td>\n      <td>0.076058</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>46_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929293</td>\n      <td>0.823330</td>\n      <td>0.178738</td>\n      <td>0.819310</td>\n      <td>0.828129</td>\n      <td>0.000659</td>\n      <td>0.146524</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>47_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.925965</td>\n      <td>0.816944</td>\n      <td>0.187925</td>\n      <td>0.816110</td>\n      <td>0.823992</td>\n      <td>0.028486</td>\n      <td>0.022405</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>48_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928744</td>\n      <td>0.819471</td>\n      <td>0.182192</td>\n      <td>0.838004</td>\n      <td>0.802784</td>\n      <td>0.005551</td>\n      <td>0.070264</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>49_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.921815</td>\n      <td>0.780488</td>\n      <td>0.201478</td>\n      <td>0.860354</td>\n      <td>0.746312</td>\n      <td>0.008412</td>\n      <td>0.000000</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "        \n",
    "df = pd.read_csv('10_ax_results.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:50:04.921709Z",
     "start_time": "2024-03-18T12:50:04.392639Z"
    }
   },
   "id": "3007ddea63082b56",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   trial_index arm_name trial_status generation_method  val_accuracy  \\\n0            0      0_0    COMPLETED             Sobol      0.934620   \n1            1      1_0    COMPLETED             Sobol      0.935624   \n2            2      2_0    COMPLETED             Sobol      0.927571   \n3            3      3_0    COMPLETED             Sobol      0.928954   \n4            4      4_0    COMPLETED             Sobol      0.935527   \n5            5      5_0    COMPLETED             Sobol      0.929572   \n6            6      6_0    COMPLETED             Sobol      0.933721   \n7            7      7_0    COMPLETED             Sobol      0.934542   \n8            8      8_0    COMPLETED           BoTorch      0.937060   \n9            9      9_0    COMPLETED           BoTorch      0.930535   \n\n     val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0  0.810570  0.166112       0.824934    0.801010  0.000540      0.162323   \n1  0.813536  0.165023       0.826492    0.805768  0.000680      0.191434   \n2  0.809681  0.183286       0.843126    0.788357  0.001139      0.182092   \n3  0.816843  0.179459       0.841151    0.798509  0.001299      0.161012   \n4  0.814086  0.164741       0.832597    0.797818  0.001760      0.192396   \n5  0.823836  0.178248       0.815446    0.833456  0.001689      0.160545   \n6  0.809359  0.168312       0.828074    0.792811  0.000599      0.176202   \n7  0.806819  0.165385       0.846475    0.778893  0.002857      0.164931   \n8  0.818937  0.159138       0.827023    0.813500  0.001552      0.185832   \n9  0.800883  0.174108       0.840776    0.768680  0.001630      0.186375   \n\n   batch_size  embedding_dim  \n0          64              7  \n1          64              7  \n2          32              5  \n3          32              6  \n4          64              5  \n5          32              5  \n6          64              6  \n7          64              6  \n8          64              7  \n9          64              7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.934620</td>\n      <td>0.810570</td>\n      <td>0.166112</td>\n      <td>0.824934</td>\n      <td>0.801010</td>\n      <td>0.000540</td>\n      <td>0.162323</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.935624</td>\n      <td>0.813536</td>\n      <td>0.165023</td>\n      <td>0.826492</td>\n      <td>0.805768</td>\n      <td>0.000680</td>\n      <td>0.191434</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.927571</td>\n      <td>0.809681</td>\n      <td>0.183286</td>\n      <td>0.843126</td>\n      <td>0.788357</td>\n      <td>0.001139</td>\n      <td>0.182092</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.928954</td>\n      <td>0.816843</td>\n      <td>0.179459</td>\n      <td>0.841151</td>\n      <td>0.798509</td>\n      <td>0.001299</td>\n      <td>0.161012</td>\n      <td>32</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.935527</td>\n      <td>0.814086</td>\n      <td>0.164741</td>\n      <td>0.832597</td>\n      <td>0.797818</td>\n      <td>0.001760</td>\n      <td>0.192396</td>\n      <td>64</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.929572</td>\n      <td>0.823836</td>\n      <td>0.178248</td>\n      <td>0.815446</td>\n      <td>0.833456</td>\n      <td>0.001689</td>\n      <td>0.160545</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>6_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.933721</td>\n      <td>0.809359</td>\n      <td>0.168312</td>\n      <td>0.828074</td>\n      <td>0.792811</td>\n      <td>0.000599</td>\n      <td>0.176202</td>\n      <td>64</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.934542</td>\n      <td>0.806819</td>\n      <td>0.165385</td>\n      <td>0.846475</td>\n      <td>0.778893</td>\n      <td>0.002857</td>\n      <td>0.164931</td>\n      <td>64</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>8_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.937060</td>\n      <td>0.818937</td>\n      <td>0.159138</td>\n      <td>0.827023</td>\n      <td>0.813500</td>\n      <td>0.001552</td>\n      <td>0.185832</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>9_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930535</td>\n      <td>0.800883</td>\n      <td>0.174108</td>\n      <td>0.840776</td>\n      <td>0.768680</td>\n      <td>0.001630</td>\n      <td>0.186375</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "        \n",
    "df = pd.read_csv('10_trials_2_results.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:50:05.124654Z",
     "start_time": "2024-03-18T12:50:05.096703Z"
    }
   },
   "id": "c1667798d34e7166",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   trial_index arm_name trial_status generation_method  val_accuracy  \\\n0            0      0_0    COMPLETED             Sobol      0.927478   \n1            1      1_0    COMPLETED             Sobol      0.932380   \n2            2      2_0    COMPLETED             Sobol      0.924233   \n3            3      3_0    COMPLETED             Sobol      0.935541   \n4            4      4_0    COMPLETED             Sobol      0.869843   \n5            5      5_0    COMPLETED             Sobol      0.924465   \n6            6      6_0    COMPLETED             Sobol      0.881841   \n7            7      7_0    COMPLETED             Sobol      0.904945   \n8            8      8_0    COMPLETED           BoTorch      0.935704   \n9            9      9_0    COMPLETED           BoTorch      0.927878   \n\n     val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0  0.775121  0.486529       0.788787    0.766161  0.000150      0.014037   \n1  0.808720  0.170111       0.810701    0.807842  0.000429      0.166330   \n2  0.779596  0.222316       0.804459    0.765111  0.000126      0.100831   \n3  0.815044  0.162917       0.824792    0.815399  0.001471      0.194957   \n4  0.657011  0.779536       0.622342    0.718749  0.000012      0.155112   \n5  0.784390  0.203939       0.801092    0.771088  0.000158      0.182599   \n6  0.670915  0.654885       0.641812    0.712430  0.000012      0.142611   \n7  0.739750  0.479592       0.724432    0.763549  0.000014      0.051640   \n8  0.814499  0.162157       0.825109    0.806146  0.001068      0.174891   \n9  0.818159  0.182842       0.823630    0.813088  0.000544      0.181448   \n\n   batch_size  embedding_dim  \n0         128              5  \n1          64              4  \n2          64              7  \n3          64             10  \n4         128              9  \n5          64              4  \n6         128              9  \n7          64              2  \n8          64              7  \n9          32              7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.927478</td>\n      <td>0.775121</td>\n      <td>0.486529</td>\n      <td>0.788787</td>\n      <td>0.766161</td>\n      <td>0.000150</td>\n      <td>0.014037</td>\n      <td>128</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.932380</td>\n      <td>0.808720</td>\n      <td>0.170111</td>\n      <td>0.810701</td>\n      <td>0.807842</td>\n      <td>0.000429</td>\n      <td>0.166330</td>\n      <td>64</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.924233</td>\n      <td>0.779596</td>\n      <td>0.222316</td>\n      <td>0.804459</td>\n      <td>0.765111</td>\n      <td>0.000126</td>\n      <td>0.100831</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.935541</td>\n      <td>0.815044</td>\n      <td>0.162917</td>\n      <td>0.824792</td>\n      <td>0.815399</td>\n      <td>0.001471</td>\n      <td>0.194957</td>\n      <td>64</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.869843</td>\n      <td>0.657011</td>\n      <td>0.779536</td>\n      <td>0.622342</td>\n      <td>0.718749</td>\n      <td>0.000012</td>\n      <td>0.155112</td>\n      <td>128</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.924465</td>\n      <td>0.784390</td>\n      <td>0.203939</td>\n      <td>0.801092</td>\n      <td>0.771088</td>\n      <td>0.000158</td>\n      <td>0.182599</td>\n      <td>64</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>6_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.881841</td>\n      <td>0.670915</td>\n      <td>0.654885</td>\n      <td>0.641812</td>\n      <td>0.712430</td>\n      <td>0.000012</td>\n      <td>0.142611</td>\n      <td>128</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.904945</td>\n      <td>0.739750</td>\n      <td>0.479592</td>\n      <td>0.724432</td>\n      <td>0.763549</td>\n      <td>0.000014</td>\n      <td>0.051640</td>\n      <td>64</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>8_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.935704</td>\n      <td>0.814499</td>\n      <td>0.162157</td>\n      <td>0.825109</td>\n      <td>0.806146</td>\n      <td>0.001068</td>\n      <td>0.174891</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>9_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.927878</td>\n      <td>0.818159</td>\n      <td>0.182842</td>\n      <td>0.823630</td>\n      <td>0.813088</td>\n      <td>0.000544</td>\n      <td>0.181448</td>\n      <td>32</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "        \n",
    "df = pd.read_csv('10_trials_results.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:50:08.075447Z",
     "start_time": "2024-03-18T12:50:08.053384Z"
    }
   },
   "id": "9d2479421aaf4655",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_index arm_name trial_status generation_method  val_accuracy  \\\n0             0      0_0    COMPLETED             Sobol      0.826649   \n1             1      1_0    COMPLETED             Sobol      0.876759   \n2             2      2_0    COMPLETED             Sobol      0.902695   \n3             3      3_0    COMPLETED             Sobol      0.880441   \n4             4      4_0    COMPLETED             Sobol      0.890542   \n5             5      5_0    COMPLETED             Sobol      0.812183   \n6             6      6_0    COMPLETED             Sobol      0.869107   \n7             7      7_0    COMPLETED             Sobol      0.906752   \n8             8      8_0    COMPLETED           BoTorch      0.904797   \n9             9      9_0    COMPLETED           BoTorch      0.906758   \n10           10     10_0    COMPLETED           BoTorch      0.906402   \n11           11     11_0    COMPLETED           BoTorch      0.905905   \n12           12     12_0    COMPLETED           BoTorch      0.883293   \n13           13     13_0    COMPLETED           BoTorch      0.921344   \n14           14     14_0    COMPLETED           BoTorch      0.920113   \n15           15     15_0    COMPLETED           BoTorch      0.931341   \n16           16     16_0    COMPLETED           BoTorch      0.931343   \n17           17     17_0    COMPLETED           BoTorch      0.930344   \n18           18     18_0    COMPLETED           BoTorch      0.928382   \n19           19     19_0    COMPLETED           BoTorch      0.930605   \n20           20     20_0    COMPLETED           BoTorch      0.924492   \n21           21     21_0    COMPLETED           BoTorch      0.924346   \n22           22     22_0    COMPLETED           BoTorch      0.930836   \n23           23     23_0    COMPLETED           BoTorch      0.931023   \n24           24     24_0    COMPLETED           BoTorch      0.931467   \n25           25     25_0    COMPLETED           BoTorch      0.931804   \n26           26     26_0    COMPLETED           BoTorch      0.927996   \n27           27     27_0    COMPLETED           BoTorch      0.930227   \n28           28     28_0    COMPLETED           BoTorch      0.932245   \n29           29     29_0    COMPLETED           BoTorch      0.928285   \n30           30     30_0    COMPLETED           BoTorch      0.930878   \n31           31     31_0    COMPLETED           BoTorch      0.931342   \n32           32     32_0    COMPLETED           BoTorch      0.928506   \n33           33     33_0    COMPLETED           BoTorch      0.929612   \n34           34     34_0    COMPLETED           BoTorch      0.928910   \n35           35     35_0    COMPLETED           BoTorch      0.928544   \n36           36     36_0    COMPLETED           BoTorch      0.925076   \n37           37     37_0    COMPLETED           BoTorch      0.929094   \n38           38     38_0    COMPLETED           BoTorch      0.931047   \n39           39     39_0    COMPLETED           BoTorch      0.922017   \n40           40     40_0    COMPLETED           BoTorch      0.929937   \n41           41     41_0    COMPLETED           BoTorch      0.931155   \n42           42     42_0    COMPLETED           BoTorch      0.929270   \n43           43     43_0    COMPLETED           BoTorch      0.923895   \n44           44     44_0    COMPLETED           BoTorch      0.932512   \n45           45     45_0    COMPLETED           BoTorch      0.924869   \n46           46     46_0    COMPLETED           BoTorch      0.929293   \n47           47     47_0    COMPLETED           BoTorch      0.925965   \n48           48     48_0    COMPLETED           BoTorch      0.928744   \n49           49     49_0    COMPLETED           BoTorch      0.921815   \n\n      val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0   0.632487  0.753653       0.609964    0.691167  0.000001      0.096349   \n1   0.810590  0.310385       0.820969    0.803478  0.001084      0.474500   \n2   0.816620  0.246278       0.832687    0.807861  0.000732      0.349536   \n3   0.813905  0.301987       0.836453    0.798037  0.016307      0.007049   \n4   0.796962  0.276153       0.806222    0.788968  0.000087      0.299568   \n5   0.670001  0.598767       0.658047    0.693985  0.000002      0.142983   \n6   0.713430  0.443356       0.724637    0.708917  0.000007      0.069830   \n7   0.825898  0.237442       0.841261    0.814406  0.001475      0.208630   \n8   0.820374  0.241392       0.838710    0.808427  0.001927      0.256962   \n9   0.827038  0.236193       0.835439    0.820312  0.001854      0.259384   \n10  0.825203  0.237058       0.836321    0.816084  0.001149      0.231935   \n11  0.823945  0.237669       0.837597    0.816305  0.001215      0.227262   \n12  0.822653  0.293328       0.826884    0.818603  0.001201      0.212927   \n13  0.829605  0.200420       0.835081    0.825778  0.003261      0.181830   \n14  0.823641  0.202998       0.838411    0.814590  0.001607      0.249531   \n15  0.825837  0.173852       0.834198    0.818445  0.002447      0.194741   \n16  0.825308  0.173988       0.836522    0.819715  0.001821      0.174627   \n17  0.820531  0.177285       0.843120    0.802851  0.002178      0.192044   \n18  0.816231  0.182909       0.840804    0.795912  0.004863      0.126065   \n19  0.827112  0.175646       0.824020    0.831566  0.001781      0.105353   \n20  0.818658  0.194072       0.803174    0.837278  0.004579      0.187194   \n21  0.810814  0.191105       0.837076    0.789558  0.003101      0.122990   \n22  0.823662  0.174842       0.834065    0.817389  0.001044      0.136415   \n23  0.822742  0.174591       0.838991    0.809842  0.001428      0.138828   \n24  0.828557  0.174540       0.822700    0.834633  0.007717      0.038824   \n25  0.826737  0.172587       0.835045    0.822671  0.006317      0.064065   \n26  0.816959  0.181844       0.837481    0.799061  0.000999      0.178062   \n27  0.820037  0.176949       0.842783    0.802240  0.001017      0.085390   \n28  0.828220  0.171595       0.834372    0.823310  0.001694      0.143371   \n29  0.825864  0.181127       0.816282    0.838710  0.006746      0.056740   \n30  0.823761  0.176168       0.837977    0.812122  0.005780      0.086623   \n31  0.824092  0.173852       0.838910    0.814581  0.002650      0.218267   \n32  0.810207  0.180810       0.846359    0.790988  0.006640      0.015518   \n33  0.810810  0.178682       0.852856    0.787512  0.003081      0.073780   \n34  0.816401  0.180558       0.842264    0.797381  0.018916      0.029491   \n35  0.822365  0.181710       0.811102    0.834620  0.001413      0.156723   \n36  0.794416  0.189463       0.857818    0.761617  0.006000      0.146366   \n37  0.820831  0.180007       0.825112    0.816698  0.000541      0.107974   \n38  0.825692  0.174317       0.829511    0.822382  0.002559      0.206471   \n39  0.778720  0.193512       0.852450    0.767553  0.010812      0.024670   \n40  0.824038  0.177415       0.827747    0.824270  0.001041      0.112319   \n41  0.825115  0.174924       0.829401    0.822980  0.002541      0.161519   \n42  0.821059  0.181067       0.825488    0.818360  0.028608      0.053110   \n43  0.802210  0.193589       0.856237    0.764752  0.004537      0.033237   \n44  0.829085  0.171494       0.833407    0.826962  0.005099      0.071276   \n45  0.807986  0.190782       0.850218    0.775249  0.007834      0.076058   \n46  0.823330  0.178738       0.819310    0.828129  0.000659      0.146524   \n47  0.816944  0.187925       0.816110    0.823992  0.028486      0.022405   \n48  0.819471  0.182192       0.838004    0.802784  0.005551      0.070264   \n49  0.780488  0.201478       0.860354    0.746312  0.008412      0.000000   \n\n    batch_size  embedding_dim  \n0           32              5  \n1            4             20  \n2            8              5  \n3            4             20  \n4            8             20  \n5            8              5  \n6           16             20  \n7            8              5  \n8            8             20  \n9            8              5  \n10           8              5  \n11           8              5  \n12           4              5  \n13          16              5  \n14          16              5  \n15          32              5  \n16          32              5  \n17          32              5  \n18          32              5  \n19          32              5  \n20          32              5  \n21          32              5  \n22          32              5  \n23          32              5  \n24          32              5  \n25          32              5  \n26          32              5  \n27          32              5  \n28          32              5  \n29          32              5  \n30          32              5  \n31          32              5  \n32          32              5  \n33          32              5  \n34          32              5  \n35          32              5  \n36          32              5  \n37          32              5  \n38          32              5  \n39          32              5  \n40          32              5  \n41          32              5  \n42          32              5  \n43          32              5  \n44          32              5  \n45          32              5  \n46          32              5  \n47          32              5  \n48          32              5  \n49          32              5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.826649</td>\n      <td>0.632487</td>\n      <td>0.753653</td>\n      <td>0.609964</td>\n      <td>0.691167</td>\n      <td>0.000001</td>\n      <td>0.096349</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.876759</td>\n      <td>0.810590</td>\n      <td>0.310385</td>\n      <td>0.820969</td>\n      <td>0.803478</td>\n      <td>0.001084</td>\n      <td>0.474500</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.902695</td>\n      <td>0.816620</td>\n      <td>0.246278</td>\n      <td>0.832687</td>\n      <td>0.807861</td>\n      <td>0.000732</td>\n      <td>0.349536</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.880441</td>\n      <td>0.813905</td>\n      <td>0.301987</td>\n      <td>0.836453</td>\n      <td>0.798037</td>\n      <td>0.016307</td>\n      <td>0.007049</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.890542</td>\n      <td>0.796962</td>\n      <td>0.276153</td>\n      <td>0.806222</td>\n      <td>0.788968</td>\n      <td>0.000087</td>\n      <td>0.299568</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.812183</td>\n      <td>0.670001</td>\n      <td>0.598767</td>\n      <td>0.658047</td>\n      <td>0.693985</td>\n      <td>0.000002</td>\n      <td>0.142983</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>6_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.869107</td>\n      <td>0.713430</td>\n      <td>0.443356</td>\n      <td>0.724637</td>\n      <td>0.708917</td>\n      <td>0.000007</td>\n      <td>0.069830</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.906752</td>\n      <td>0.825898</td>\n      <td>0.237442</td>\n      <td>0.841261</td>\n      <td>0.814406</td>\n      <td>0.001475</td>\n      <td>0.208630</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>8_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.904797</td>\n      <td>0.820374</td>\n      <td>0.241392</td>\n      <td>0.838710</td>\n      <td>0.808427</td>\n      <td>0.001927</td>\n      <td>0.256962</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>9_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.906758</td>\n      <td>0.827038</td>\n      <td>0.236193</td>\n      <td>0.835439</td>\n      <td>0.820312</td>\n      <td>0.001854</td>\n      <td>0.259384</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>10_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.906402</td>\n      <td>0.825203</td>\n      <td>0.237058</td>\n      <td>0.836321</td>\n      <td>0.816084</td>\n      <td>0.001149</td>\n      <td>0.231935</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>11_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.905905</td>\n      <td>0.823945</td>\n      <td>0.237669</td>\n      <td>0.837597</td>\n      <td>0.816305</td>\n      <td>0.001215</td>\n      <td>0.227262</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>12_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.883293</td>\n      <td>0.822653</td>\n      <td>0.293328</td>\n      <td>0.826884</td>\n      <td>0.818603</td>\n      <td>0.001201</td>\n      <td>0.212927</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>13_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.921344</td>\n      <td>0.829605</td>\n      <td>0.200420</td>\n      <td>0.835081</td>\n      <td>0.825778</td>\n      <td>0.003261</td>\n      <td>0.181830</td>\n      <td>16</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>14_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.920113</td>\n      <td>0.823641</td>\n      <td>0.202998</td>\n      <td>0.838411</td>\n      <td>0.814590</td>\n      <td>0.001607</td>\n      <td>0.249531</td>\n      <td>16</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>15_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931341</td>\n      <td>0.825837</td>\n      <td>0.173852</td>\n      <td>0.834198</td>\n      <td>0.818445</td>\n      <td>0.002447</td>\n      <td>0.194741</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>16_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931343</td>\n      <td>0.825308</td>\n      <td>0.173988</td>\n      <td>0.836522</td>\n      <td>0.819715</td>\n      <td>0.001821</td>\n      <td>0.174627</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>17_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930344</td>\n      <td>0.820531</td>\n      <td>0.177285</td>\n      <td>0.843120</td>\n      <td>0.802851</td>\n      <td>0.002178</td>\n      <td>0.192044</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>18_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928382</td>\n      <td>0.816231</td>\n      <td>0.182909</td>\n      <td>0.840804</td>\n      <td>0.795912</td>\n      <td>0.004863</td>\n      <td>0.126065</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>19_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930605</td>\n      <td>0.827112</td>\n      <td>0.175646</td>\n      <td>0.824020</td>\n      <td>0.831566</td>\n      <td>0.001781</td>\n      <td>0.105353</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>20_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924492</td>\n      <td>0.818658</td>\n      <td>0.194072</td>\n      <td>0.803174</td>\n      <td>0.837278</td>\n      <td>0.004579</td>\n      <td>0.187194</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>21_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924346</td>\n      <td>0.810814</td>\n      <td>0.191105</td>\n      <td>0.837076</td>\n      <td>0.789558</td>\n      <td>0.003101</td>\n      <td>0.122990</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>22_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930836</td>\n      <td>0.823662</td>\n      <td>0.174842</td>\n      <td>0.834065</td>\n      <td>0.817389</td>\n      <td>0.001044</td>\n      <td>0.136415</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>23_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931023</td>\n      <td>0.822742</td>\n      <td>0.174591</td>\n      <td>0.838991</td>\n      <td>0.809842</td>\n      <td>0.001428</td>\n      <td>0.138828</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>24_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931467</td>\n      <td>0.828557</td>\n      <td>0.174540</td>\n      <td>0.822700</td>\n      <td>0.834633</td>\n      <td>0.007717</td>\n      <td>0.038824</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>25_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931804</td>\n      <td>0.826737</td>\n      <td>0.172587</td>\n      <td>0.835045</td>\n      <td>0.822671</td>\n      <td>0.006317</td>\n      <td>0.064065</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>26_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.927996</td>\n      <td>0.816959</td>\n      <td>0.181844</td>\n      <td>0.837481</td>\n      <td>0.799061</td>\n      <td>0.000999</td>\n      <td>0.178062</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>27_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930227</td>\n      <td>0.820037</td>\n      <td>0.176949</td>\n      <td>0.842783</td>\n      <td>0.802240</td>\n      <td>0.001017</td>\n      <td>0.085390</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>28_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.932245</td>\n      <td>0.828220</td>\n      <td>0.171595</td>\n      <td>0.834372</td>\n      <td>0.823310</td>\n      <td>0.001694</td>\n      <td>0.143371</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>29_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928285</td>\n      <td>0.825864</td>\n      <td>0.181127</td>\n      <td>0.816282</td>\n      <td>0.838710</td>\n      <td>0.006746</td>\n      <td>0.056740</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>30_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.930878</td>\n      <td>0.823761</td>\n      <td>0.176168</td>\n      <td>0.837977</td>\n      <td>0.812122</td>\n      <td>0.005780</td>\n      <td>0.086623</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>31_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931342</td>\n      <td>0.824092</td>\n      <td>0.173852</td>\n      <td>0.838910</td>\n      <td>0.814581</td>\n      <td>0.002650</td>\n      <td>0.218267</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>32_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928506</td>\n      <td>0.810207</td>\n      <td>0.180810</td>\n      <td>0.846359</td>\n      <td>0.790988</td>\n      <td>0.006640</td>\n      <td>0.015518</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>33_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929612</td>\n      <td>0.810810</td>\n      <td>0.178682</td>\n      <td>0.852856</td>\n      <td>0.787512</td>\n      <td>0.003081</td>\n      <td>0.073780</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>34_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928910</td>\n      <td>0.816401</td>\n      <td>0.180558</td>\n      <td>0.842264</td>\n      <td>0.797381</td>\n      <td>0.018916</td>\n      <td>0.029491</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>35_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928544</td>\n      <td>0.822365</td>\n      <td>0.181710</td>\n      <td>0.811102</td>\n      <td>0.834620</td>\n      <td>0.001413</td>\n      <td>0.156723</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>36_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.925076</td>\n      <td>0.794416</td>\n      <td>0.189463</td>\n      <td>0.857818</td>\n      <td>0.761617</td>\n      <td>0.006000</td>\n      <td>0.146366</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>37_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929094</td>\n      <td>0.820831</td>\n      <td>0.180007</td>\n      <td>0.825112</td>\n      <td>0.816698</td>\n      <td>0.000541</td>\n      <td>0.107974</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>38_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931047</td>\n      <td>0.825692</td>\n      <td>0.174317</td>\n      <td>0.829511</td>\n      <td>0.822382</td>\n      <td>0.002559</td>\n      <td>0.206471</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>39_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.922017</td>\n      <td>0.778720</td>\n      <td>0.193512</td>\n      <td>0.852450</td>\n      <td>0.767553</td>\n      <td>0.010812</td>\n      <td>0.024670</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>40_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929937</td>\n      <td>0.824038</td>\n      <td>0.177415</td>\n      <td>0.827747</td>\n      <td>0.824270</td>\n      <td>0.001041</td>\n      <td>0.112319</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>41_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.931155</td>\n      <td>0.825115</td>\n      <td>0.174924</td>\n      <td>0.829401</td>\n      <td>0.822980</td>\n      <td>0.002541</td>\n      <td>0.161519</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>42_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929270</td>\n      <td>0.821059</td>\n      <td>0.181067</td>\n      <td>0.825488</td>\n      <td>0.818360</td>\n      <td>0.028608</td>\n      <td>0.053110</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>43_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.923895</td>\n      <td>0.802210</td>\n      <td>0.193589</td>\n      <td>0.856237</td>\n      <td>0.764752</td>\n      <td>0.004537</td>\n      <td>0.033237</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>44_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.932512</td>\n      <td>0.829085</td>\n      <td>0.171494</td>\n      <td>0.833407</td>\n      <td>0.826962</td>\n      <td>0.005099</td>\n      <td>0.071276</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>45_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924869</td>\n      <td>0.807986</td>\n      <td>0.190782</td>\n      <td>0.850218</td>\n      <td>0.775249</td>\n      <td>0.007834</td>\n      <td>0.076058</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>46_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929293</td>\n      <td>0.823330</td>\n      <td>0.178738</td>\n      <td>0.819310</td>\n      <td>0.828129</td>\n      <td>0.000659</td>\n      <td>0.146524</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>47_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.925965</td>\n      <td>0.816944</td>\n      <td>0.187925</td>\n      <td>0.816110</td>\n      <td>0.823992</td>\n      <td>0.028486</td>\n      <td>0.022405</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>48_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928744</td>\n      <td>0.819471</td>\n      <td>0.182192</td>\n      <td>0.838004</td>\n      <td>0.802784</td>\n      <td>0.005551</td>\n      <td>0.070264</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>49_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.921815</td>\n      <td>0.780488</td>\n      <td>0.201478</td>\n      <td>0.860354</td>\n      <td>0.746312</td>\n      <td>0.008412</td>\n      <td>0.000000</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "        \n",
    "df = pd.read_csv('50_ax_results.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:50:11.388591Z",
     "start_time": "2024-03-18T12:50:11.346393Z"
    }
   },
   "id": "fed453775d12fcb8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c284abfa2a92f00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# CSV\n",
    "csv_files = ['10_ax_results.csv', '10_trials_2_results.csv', '10_trials_results.csv', '50_ax_results.csv']\n",
    "\n",
    "# PandasCSV\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "# concatDataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# DataFrameCSV\n",
    "combined_df.to_csv('all_ax.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:53:26.017402Z",
     "start_time": "2024-03-18T12:53:25.996784Z"
    }
   },
   "id": "99b8afc9458721c7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     trial_index arm_name trial_status generation_method  val_accuracy  \\\n0              0      0_0    COMPLETED             Sobol      0.826649   \n1              1      1_0    COMPLETED             Sobol      0.876759   \n2              2      2_0    COMPLETED             Sobol      0.902695   \n3              3      3_0    COMPLETED             Sobol      0.880441   \n4              4      4_0    COMPLETED             Sobol      0.890542   \n..           ...      ...          ...               ...           ...   \n115           45     45_0    COMPLETED           BoTorch      0.924869   \n116           46     46_0    COMPLETED           BoTorch      0.929293   \n117           47     47_0    COMPLETED           BoTorch      0.925965   \n118           48     48_0    COMPLETED           BoTorch      0.928744   \n119           49     49_0    COMPLETED           BoTorch      0.921815   \n\n       val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0    0.632487  0.753653       0.609964    0.691167  0.000001      0.096349   \n1    0.810590  0.310385       0.820969    0.803478  0.001084      0.474500   \n2    0.816620  0.246278       0.832687    0.807861  0.000732      0.349536   \n3    0.813905  0.301987       0.836453    0.798037  0.016307      0.007049   \n4    0.796962  0.276153       0.806222    0.788968  0.000087      0.299568   \n..        ...       ...            ...         ...       ...           ...   \n115  0.807986  0.190782       0.850218    0.775249  0.007834      0.076058   \n116  0.823330  0.178738       0.819310    0.828129  0.000659      0.146524   \n117  0.816944  0.187925       0.816110    0.823992  0.028486      0.022405   \n118  0.819471  0.182192       0.838004    0.802784  0.005551      0.070264   \n119  0.780488  0.201478       0.860354    0.746312  0.008412      0.000000   \n\n     batch_size  embedding_dim  \n0            32              5  \n1             4             20  \n2             8              5  \n3             4             20  \n4             8             20  \n..          ...            ...  \n115          32              5  \n116          32              5  \n117          32              5  \n118          32              5  \n119          32              5  \n\n[120 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.826649</td>\n      <td>0.632487</td>\n      <td>0.753653</td>\n      <td>0.609964</td>\n      <td>0.691167</td>\n      <td>0.000001</td>\n      <td>0.096349</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.876759</td>\n      <td>0.810590</td>\n      <td>0.310385</td>\n      <td>0.820969</td>\n      <td>0.803478</td>\n      <td>0.001084</td>\n      <td>0.474500</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.902695</td>\n      <td>0.816620</td>\n      <td>0.246278</td>\n      <td>0.832687</td>\n      <td>0.807861</td>\n      <td>0.000732</td>\n      <td>0.349536</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.880441</td>\n      <td>0.813905</td>\n      <td>0.301987</td>\n      <td>0.836453</td>\n      <td>0.798037</td>\n      <td>0.016307</td>\n      <td>0.007049</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.890542</td>\n      <td>0.796962</td>\n      <td>0.276153</td>\n      <td>0.806222</td>\n      <td>0.788968</td>\n      <td>0.000087</td>\n      <td>0.299568</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>45</td>\n      <td>45_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.924869</td>\n      <td>0.807986</td>\n      <td>0.190782</td>\n      <td>0.850218</td>\n      <td>0.775249</td>\n      <td>0.007834</td>\n      <td>0.076058</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>46</td>\n      <td>46_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.929293</td>\n      <td>0.823330</td>\n      <td>0.178738</td>\n      <td>0.819310</td>\n      <td>0.828129</td>\n      <td>0.000659</td>\n      <td>0.146524</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>47</td>\n      <td>47_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.925965</td>\n      <td>0.816944</td>\n      <td>0.187925</td>\n      <td>0.816110</td>\n      <td>0.823992</td>\n      <td>0.028486</td>\n      <td>0.022405</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>48</td>\n      <td>48_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.928744</td>\n      <td>0.819471</td>\n      <td>0.182192</td>\n      <td>0.838004</td>\n      <td>0.802784</td>\n      <td>0.005551</td>\n      <td>0.070264</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>49</td>\n      <td>49_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.921815</td>\n      <td>0.780488</td>\n      <td>0.201478</td>\n      <td>0.860354</td>\n      <td>0.746312</td>\n      <td>0.008412</td>\n      <td>0.000000</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows  13 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:55:11.498886Z",
     "start_time": "2024-03-18T12:55:11.471973Z"
    }
   },
   "id": "53088a6304deeba0",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_unique = combined_df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:55:33.482233Z",
     "start_time": "2024-03-18T12:55:33.463043Z"
    }
   },
   "id": "df299e49f1561feb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_index arm_name trial_status generation_method  val_accuracy  \\\n0             0      0_0    COMPLETED             Sobol      0.826649   \n1             1      1_0    COMPLETED             Sobol      0.876759   \n2             2      2_0    COMPLETED             Sobol      0.902695   \n3             3      3_0    COMPLETED             Sobol      0.880441   \n4             4      4_0    COMPLETED             Sobol      0.890542   \n..          ...      ...          ...               ...           ...   \n65            5      5_0    COMPLETED             Sobol      0.924465   \n66            6      6_0    COMPLETED             Sobol      0.881841   \n67            7      7_0    COMPLETED             Sobol      0.904945   \n68            8      8_0    COMPLETED           BoTorch      0.935704   \n69            9      9_0    COMPLETED           BoTorch      0.927878   \n\n      val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0   0.632487  0.753653       0.609964    0.691167  0.000001      0.096349   \n1   0.810590  0.310385       0.820969    0.803478  0.001084      0.474500   \n2   0.816620  0.246278       0.832687    0.807861  0.000732      0.349536   \n3   0.813905  0.301987       0.836453    0.798037  0.016307      0.007049   \n4   0.796962  0.276153       0.806222    0.788968  0.000087      0.299568   \n..       ...       ...            ...         ...       ...           ...   \n65  0.784390  0.203939       0.801092    0.771088  0.000158      0.182599   \n66  0.670915  0.654885       0.641812    0.712430  0.000012      0.142611   \n67  0.739750  0.479592       0.724432    0.763549  0.000014      0.051640   \n68  0.814499  0.162157       0.825109    0.806146  0.001068      0.174891   \n69  0.818159  0.182842       0.823630    0.813088  0.000544      0.181448   \n\n    batch_size  embedding_dim  \n0           32              5  \n1            4             20  \n2            8              5  \n3            4             20  \n4            8             20  \n..         ...            ...  \n65          64              4  \n66         128              9  \n67          64              2  \n68          64              7  \n69          32              7  \n\n[70 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.826649</td>\n      <td>0.632487</td>\n      <td>0.753653</td>\n      <td>0.609964</td>\n      <td>0.691167</td>\n      <td>0.000001</td>\n      <td>0.096349</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.876759</td>\n      <td>0.810590</td>\n      <td>0.310385</td>\n      <td>0.820969</td>\n      <td>0.803478</td>\n      <td>0.001084</td>\n      <td>0.474500</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.902695</td>\n      <td>0.816620</td>\n      <td>0.246278</td>\n      <td>0.832687</td>\n      <td>0.807861</td>\n      <td>0.000732</td>\n      <td>0.349536</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.880441</td>\n      <td>0.813905</td>\n      <td>0.301987</td>\n      <td>0.836453</td>\n      <td>0.798037</td>\n      <td>0.016307</td>\n      <td>0.007049</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.890542</td>\n      <td>0.796962</td>\n      <td>0.276153</td>\n      <td>0.806222</td>\n      <td>0.788968</td>\n      <td>0.000087</td>\n      <td>0.299568</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>5</td>\n      <td>5_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.924465</td>\n      <td>0.784390</td>\n      <td>0.203939</td>\n      <td>0.801092</td>\n      <td>0.771088</td>\n      <td>0.000158</td>\n      <td>0.182599</td>\n      <td>64</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>6</td>\n      <td>6_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.881841</td>\n      <td>0.670915</td>\n      <td>0.654885</td>\n      <td>0.641812</td>\n      <td>0.712430</td>\n      <td>0.000012</td>\n      <td>0.142611</td>\n      <td>128</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>7</td>\n      <td>7_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.904945</td>\n      <td>0.739750</td>\n      <td>0.479592</td>\n      <td>0.724432</td>\n      <td>0.763549</td>\n      <td>0.000014</td>\n      <td>0.051640</td>\n      <td>64</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>8</td>\n      <td>8_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.935704</td>\n      <td>0.814499</td>\n      <td>0.162157</td>\n      <td>0.825109</td>\n      <td>0.806146</td>\n      <td>0.001068</td>\n      <td>0.174891</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>9</td>\n      <td>9_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.927878</td>\n      <td>0.818159</td>\n      <td>0.182842</td>\n      <td>0.823630</td>\n      <td>0.813088</td>\n      <td>0.000544</td>\n      <td>0.181448</td>\n      <td>32</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows  13 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:55:37.275986Z",
     "start_time": "2024-03-18T12:55:37.254924Z"
    }
   },
   "id": "8e2e6015dd3da5af",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_unique.to_csv('all_ax.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:55:57.512839Z",
     "start_time": "2024-03-18T12:55:57.495832Z"
    }
   },
   "id": "ac2ac130aec13a7d",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d325d13dc8f755c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_index arm_name trial_status generation_method  val_accuracy  \\\n0             0      0_0    COMPLETED             Sobol      0.826649   \n1             1      1_0    COMPLETED             Sobol      0.876759   \n2             2      2_0    COMPLETED             Sobol      0.902695   \n3             3      3_0    COMPLETED             Sobol      0.880441   \n4             4      4_0    COMPLETED             Sobol      0.890542   \n..          ...      ...          ...               ...           ...   \n65            5      5_0    COMPLETED             Sobol      0.924465   \n66            6      6_0    COMPLETED             Sobol      0.881841   \n67            7      7_0    COMPLETED             Sobol      0.904945   \n68            8      8_0    COMPLETED           BoTorch      0.935704   \n69            9      9_0    COMPLETED           BoTorch      0.927878   \n\n      val_f1  val_loss  val_precision  val_recall        lr  dropout_rate  \\\n0   0.632487  0.753653       0.609964    0.691167  0.000001      0.096349   \n1   0.810590  0.310385       0.820969    0.803478  0.001084      0.474500   \n2   0.816620  0.246278       0.832687    0.807861  0.000732      0.349536   \n3   0.813905  0.301987       0.836453    0.798037  0.016307      0.007049   \n4   0.796962  0.276153       0.806222    0.788968  0.000087      0.299568   \n..       ...       ...            ...         ...       ...           ...   \n65  0.784390  0.203939       0.801092    0.771088  0.000158      0.182599   \n66  0.670915  0.654885       0.641812    0.712430  0.000012      0.142611   \n67  0.739750  0.479592       0.724432    0.763549  0.000014      0.051640   \n68  0.814499  0.162157       0.825109    0.806146  0.001068      0.174891   \n69  0.818159  0.182842       0.823630    0.813088  0.000544      0.181448   \n\n    batch_size  embedding_dim  \n0           32              5  \n1            4             20  \n2            8              5  \n3            4             20  \n4            8             20  \n..         ...            ...  \n65          64              4  \n66         128              9  \n67          64              2  \n68          64              7  \n69          32              7  \n\n[70 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_index</th>\n      <th>arm_name</th>\n      <th>trial_status</th>\n      <th>generation_method</th>\n      <th>val_accuracy</th>\n      <th>val_f1</th>\n      <th>val_loss</th>\n      <th>val_precision</th>\n      <th>val_recall</th>\n      <th>lr</th>\n      <th>dropout_rate</th>\n      <th>batch_size</th>\n      <th>embedding_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.826649</td>\n      <td>0.632487</td>\n      <td>0.753653</td>\n      <td>0.609964</td>\n      <td>0.691167</td>\n      <td>0.000001</td>\n      <td>0.096349</td>\n      <td>32</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.876759</td>\n      <td>0.810590</td>\n      <td>0.310385</td>\n      <td>0.820969</td>\n      <td>0.803478</td>\n      <td>0.001084</td>\n      <td>0.474500</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.902695</td>\n      <td>0.816620</td>\n      <td>0.246278</td>\n      <td>0.832687</td>\n      <td>0.807861</td>\n      <td>0.000732</td>\n      <td>0.349536</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.880441</td>\n      <td>0.813905</td>\n      <td>0.301987</td>\n      <td>0.836453</td>\n      <td>0.798037</td>\n      <td>0.016307</td>\n      <td>0.007049</td>\n      <td>4</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.890542</td>\n      <td>0.796962</td>\n      <td>0.276153</td>\n      <td>0.806222</td>\n      <td>0.788968</td>\n      <td>0.000087</td>\n      <td>0.299568</td>\n      <td>8</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>5</td>\n      <td>5_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.924465</td>\n      <td>0.784390</td>\n      <td>0.203939</td>\n      <td>0.801092</td>\n      <td>0.771088</td>\n      <td>0.000158</td>\n      <td>0.182599</td>\n      <td>64</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>6</td>\n      <td>6_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.881841</td>\n      <td>0.670915</td>\n      <td>0.654885</td>\n      <td>0.641812</td>\n      <td>0.712430</td>\n      <td>0.000012</td>\n      <td>0.142611</td>\n      <td>128</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>7</td>\n      <td>7_0</td>\n      <td>COMPLETED</td>\n      <td>Sobol</td>\n      <td>0.904945</td>\n      <td>0.739750</td>\n      <td>0.479592</td>\n      <td>0.724432</td>\n      <td>0.763549</td>\n      <td>0.000014</td>\n      <td>0.051640</td>\n      <td>64</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>8</td>\n      <td>8_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.935704</td>\n      <td>0.814499</td>\n      <td>0.162157</td>\n      <td>0.825109</td>\n      <td>0.806146</td>\n      <td>0.001068</td>\n      <td>0.174891</td>\n      <td>64</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>9</td>\n      <td>9_0</td>\n      <td>COMPLETED</td>\n      <td>BoTorch</td>\n      <td>0.927878</td>\n      <td>0.818159</td>\n      <td>0.182842</td>\n      <td>0.823630</td>\n      <td>0.813088</td>\n      <td>0.000544</td>\n      <td>0.181448</td>\n      <td>32</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows  13 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "        \n",
    "all_ax = pd.read_csv('all_ax.csv')\n",
    "all_ax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:55:58.619764Z",
     "start_time": "2024-03-18T12:55:58.602020Z"
    }
   },
   "id": "cce8574c9fe8d05f",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "41cf87b27bf38fbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
